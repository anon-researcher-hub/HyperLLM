#!/usr/bin/env python3
"""
è¶…å›¾è°±ç›¸ä¼¼æ€§åˆ†ææ¨¡å—
Hypergraph Spectral Similarity

åŸºäºè®ºæ–‡:
1. Chung, F. R. (1997).
   "Spectral Graph Theory."
   American Mathematical Society.

2. Zhou, D., Huang, J., & SchÃ¶lkopf, B. (2007).
   "Learning with hypergraphs: Clustering, classification, and embedding."
   NIPS, 19, 1601-1608.

3. Louis, A. (2015).
   "Hypergraph Markov Operators, Eigenvalues and Approximation Algorithms."
   STOC 2015.

å®ç°è¶…å›¾è°±åˆ†æ:
- é‚»æ¥çŸ©é˜µè°±åˆ†æ
- æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µè°±åˆ†æ
- è°±è·ç¦»è®¡ç®—
- ç‰¹å¾å€¼åˆ†å¸ƒ
"""

import numpy as np
import json
from collections import defaultdict
from typing import List, Dict, Set, Tuple
from scipy import sparse
from scipy.sparse import linalg as sp_linalg
from scipy.spatial.distance import euclidean, cosine


class HypergraphSpectralSimilarity:
    """è¶…å›¾è°±ç›¸ä¼¼æ€§åˆ†æå™¨"""
    
    def __init__(self, hypergraph_file: str):
        """
        åˆå§‹åŒ–è¶…å›¾
        
        Args:
            hypergraph_file: è¶…å›¾æ–‡ä»¶è·¯å¾„
        """
        self.hypergraphs = self._load_hypergraph(hypergraph_file)
        self.nodes = self._extract_nodes()
        self.node_to_idx = {node: idx for idx, node in enumerate(sorted(self.nodes))}
        self.idx_to_node = {idx: node for node, idx in self.node_to_idx.items()}
        
        # æ„å»ºè¶…å›¾è¡¨ç¤ºçŸ©é˜µ
        self.incidence_matrix = self._build_incidence_matrix()
        
    def _load_hypergraph(self, file_path: str) -> List[Set[str]]:
        """åŠ è½½è¶…å›¾æ–‡ä»¶"""
        hyperedges = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                nodes = set(line.strip().split())
                if len(nodes) > 0:
                    hyperedges.append(nodes)
        return hyperedges
    
    def _extract_nodes(self) -> Set[str]:
        """æå–æ‰€æœ‰èŠ‚ç‚¹"""
        nodes = set()
        for edge in self.hypergraphs:
            nodes.update(edge)
        return nodes
    
    def _build_incidence_matrix(self) -> sparse.csr_matrix:
        """
        æ„å»ºå…³è”çŸ©é˜µ H
        
        H[i,e] = 1 if node i âˆˆ hyperedge e, else 0
        
        å½¢çŠ¶: |V| Ã— |E|
        """
        n_nodes = len(self.nodes)
        n_edges = len(self.hypergraphs)
        
        row_indices = []
        col_indices = []
        
        for edge_idx, edge in enumerate(self.hypergraphs):
            for node in edge:
                node_idx = self.node_to_idx[node]
                row_indices.append(node_idx)
                col_indices.append(edge_idx)
        
        data = np.ones(len(row_indices))
        H = sparse.csr_matrix(
            (data, (row_indices, col_indices)),
            shape=(n_nodes, n_edges)
        )
        
        return H
    
    def compute_adjacency_matrix(self) -> sparse.csr_matrix:
        """
        è®¡ç®—è¶…å›¾é‚»æ¥çŸ©é˜µ A
        
        åŸºäº Zhou et al. (2007) çš„å®šä¹‰:
        A = H * W * D_e^(-1) * H^T
        
        å…¶ä¸­:
        - H: å…³è”çŸ©é˜µ
        - W: è¶…è¾¹æƒé‡å¯¹è§’çŸ©é˜µ (è¿™é‡Œè®¾ä¸ºå•ä½çŸ©é˜µ)
        - D_e: è¶…è¾¹åº¦å¯¹è§’çŸ©é˜µï¼ŒD_e(e,e) = |e|
        """
        print("  - è®¡ç®—é‚»æ¥çŸ©é˜µ...")
        
        H = self.incidence_matrix
        
        # è®¡ç®—è¶…è¾¹åº¦ (æ¯ä¸ªè¶…è¾¹åŒ…å«çš„èŠ‚ç‚¹æ•°)
        edge_degrees = np.array(H.sum(axis=0)).flatten()
        edge_degrees[edge_degrees == 0] = 1  # é¿å…é™¤é›¶
        
        # D_e^(-1)
        D_e_inv = sparse.diags(1.0 / edge_degrees)
        
        # A = H * D_e^(-1) * H^T
        A = H @ D_e_inv @ H.T
        
        # ç§»é™¤å¯¹è§’çº¿ï¼ˆè‡ªç¯ï¼‰
        A.setdiag(0)
        A.eliminate_zeros()
        
        return A
    
    def compute_laplacian_matrix(self, normalized: bool = True) -> sparse.csr_matrix:
        """
        è®¡ç®—è¶…å›¾æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ L
        
        åŸºäº Zhou et al. (2007) å’Œ Chung (1997):
        
        æœªå½’ä¸€åŒ–æ‹‰æ™®æ‹‰æ–¯:
        L = D_v - A
        
        å½’ä¸€åŒ–æ‹‰æ™®æ‹‰æ–¯ (æ¨è):
        L_norm = D_v^(-1/2) * L * D_v^(-1/2) = I - D_v^(-1/2) * A * D_v^(-1/2)
        
        å…¶ä¸­ D_v æ˜¯èŠ‚ç‚¹åº¦å¯¹è§’çŸ©é˜µ
        """
        print("  - è®¡ç®—æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ...")
        
        A = self.compute_adjacency_matrix()
        
        # è®¡ç®—èŠ‚ç‚¹åº¦
        node_degrees = np.array(A.sum(axis=1)).flatten()
        node_degrees[node_degrees == 0] = 1  # é¿å…é™¤é›¶
        
        D_v = sparse.diags(node_degrees)
        
        if normalized:
            # å½’ä¸€åŒ–æ‹‰æ™®æ‹‰æ–¯
            D_v_inv_sqrt = sparse.diags(1.0 / np.sqrt(node_degrees))
            L = sparse.eye(len(self.nodes)) - D_v_inv_sqrt @ A @ D_v_inv_sqrt
        else:
            # æœªå½’ä¸€åŒ–æ‹‰æ™®æ‹‰æ–¯
            L = D_v - A
        
        return L
    
    def compute_eigenvalues(self, matrix_type: str = 'laplacian', k: int = 50) -> np.ndarray:
        """
        è®¡ç®—ç‰¹å¾å€¼
        
        Args:
            matrix_type: 'adjacency' æˆ– 'laplacian'
            k: è¦è®¡ç®—çš„ç‰¹å¾å€¼æ•°é‡
        
        è¿”å›æ’åºåçš„ç‰¹å¾å€¼æ•°ç»„
        """
        print(f"  - è®¡ç®—{matrix_type}ç‰¹å¾å€¼...")
        
        if matrix_type == 'adjacency':
            matrix = self.compute_adjacency_matrix()
            # è®¡ç®—æœ€å¤§çš„kä¸ªç‰¹å¾å€¼
            k_actual = min(k, matrix.shape[0] - 2)
            if k_actual < 1:
                return np.array([])
            eigenvalues, _ = sp_linalg.eigs(matrix, k=k_actual, which='LM')
        else:  # laplacian
            matrix = self.compute_laplacian_matrix(normalized=True)
            # è®¡ç®—æœ€å°çš„kä¸ªç‰¹å¾å€¼
            k_actual = min(k, matrix.shape[0] - 2)
            if k_actual < 1:
                return np.array([])
            eigenvalues, _ = sp_linalg.eigsh(matrix, k=k_actual, which='SM')
        
        # åªä¿ç•™å®éƒ¨å¹¶æ’åº
        eigenvalues = np.real(eigenvalues)
        eigenvalues = np.sort(eigenvalues)
        
        return eigenvalues
    
    def compute_spectral_gap(self, eigenvalues: np.ndarray) -> float:
        """
        è®¡ç®—è°±é—´éš™ (Spectral Gap)
        
        å®šä¹‰: Î»_2 - Î»_1 (æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ)
        
        è°±é—´éš™è¶Šå¤§ï¼Œå›¾çš„è¿é€šæ€§è¶Šå¥½
        
        åŸºäº Chung (1997)
        """
        if len(eigenvalues) < 2:
            return 0.0
        
        return float(eigenvalues[1] - eigenvalues[0])
    
    def compute_spectral_radius(self, eigenvalues: np.ndarray) -> float:
        """
        è®¡ç®—è°±åŠå¾„ (Spectral Radius)
        
        å®šä¹‰: max|Î»_i|
        
        åŸºäºå›¾è®ºåŸºç¡€ç†è®º
        """
        if len(eigenvalues) == 0:
            return 0.0
        
        return float(np.max(np.abs(eigenvalues)))
    
    def compute_eigenvalue_statistics(self, eigenvalues: np.ndarray) -> Dict:
        """
        è®¡ç®—ç‰¹å¾å€¼ç»Ÿè®¡ä¿¡æ¯
        
        åŒ…æ‹¬å‡å€¼ã€æ ‡å‡†å·®ã€ååº¦ã€å³°åº¦ç­‰
        """
        if len(eigenvalues) == 0:
            return {
                'mean': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0,
                'median': 0.0, 'skewness': 0.0, 'kurtosis': 0.0
            }
        
        from scipy import stats
        
        return {
            'mean': float(np.mean(eigenvalues)),
            'std': float(np.std(eigenvalues)),
            'min': float(np.min(eigenvalues)),
            'max': float(np.max(eigenvalues)),
            'median': float(np.median(eigenvalues)),
            'skewness': float(stats.skew(eigenvalues)),
            'kurtosis': float(stats.kurtosis(eigenvalues)),
            'percentile_25': float(np.percentile(eigenvalues, 25)),
            'percentile_75': float(np.percentile(eigenvalues, 75))
        }
    
    def compute_spectral_entropy(self, eigenvalues: np.ndarray) -> float:
        """
        è®¡ç®—è°±ç†µ (Spectral Entropy)
        
        å…¬å¼ (åŸºäº information theory):
        H = -Î£ (Î»_i / Î£Î»_j) * log(Î»_i / Î£Î»_j)
        
        è°±ç†µè¡¡é‡ç‰¹å¾å€¼åˆ†å¸ƒçš„å‡åŒ€æ€§
        """
        # ä½¿ç”¨ç»å¯¹å€¼é¿å…è´Ÿæ•°
        abs_eigenvalues = np.abs(eigenvalues)
        
        # å½’ä¸€åŒ–
        total = np.sum(abs_eigenvalues)
        if total == 0:
            return 0.0
        
        probs = abs_eigenvalues / total
        probs = probs[probs > 0]  # ç§»é™¤é›¶å€¼
        
        entropy = -np.sum(probs * np.log2(probs))
        
        return float(entropy)
    
    def compute_trace_statistics(self) -> Dict:
        """
        è®¡ç®—è¿¹ç»Ÿè®¡ (Trace Statistics)
        
        Tr(A) = Î£Î»_i
        Tr(A^2) = Î£Î»_i^2
        
        è¿¹ä¸å›¾çš„ç»“æ„ç‰¹æ€§ç›¸å…³
        """
        print("  - è®¡ç®—è¿¹ç»Ÿè®¡...")
        
        A = self.compute_adjacency_matrix()
        
        # è®¡ç®— Tr(A) = Î£a_ii (å¯¹è§’çº¿å’Œ)
        trace_A = A.diagonal().sum()
        
        # è®¡ç®— Tr(A^2) = Î£(A^2)_ii
        A_squared = A @ A
        trace_A2 = A_squared.diagonal().sum()
        
        # è®¡ç®— Tr(A^3) (ä¸‰è§’å½¢æ•°é‡ç›¸å…³)
        A_cubed = A_squared @ A
        trace_A3 = A_cubed.diagonal().sum()
        
        return {
            'trace_A': float(trace_A),
            'trace_A2': float(trace_A2),
            'trace_A3': float(trace_A3),
            'normalized_trace_A2': float(trace_A2 / len(self.nodes)) if len(self.nodes) > 0 else 0.0
        }
    
    def compute_all_metrics(self, k_eigenvalues: int = 50) -> Dict:
        """
        è®¡ç®—æ‰€æœ‰è°±æŒ‡æ ‡
        
        Args:
            k_eigenvalues: è¦è®¡ç®—çš„ç‰¹å¾å€¼æ•°é‡
        """
        print("ğŸ“Š è®¡ç®—è¶…å›¾è°±ç›¸ä¼¼æ€§...")
        
        # è®¡ç®—ç‰¹å¾å€¼
        print("  - é‚»æ¥çŸ©é˜µè°±åˆ†æ...")
        adj_eigenvalues = self.compute_eigenvalues('adjacency', k_eigenvalues)
        
        print("  - æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µè°±åˆ†æ...")
        lap_eigenvalues = self.compute_eigenvalues('laplacian', k_eigenvalues)
        
        results = {
            'adjacency_spectrum': {
                'eigenvalues': adj_eigenvalues.tolist(),
                'spectral_radius': self.compute_spectral_radius(adj_eigenvalues),
                'statistics': self.compute_eigenvalue_statistics(adj_eigenvalues),
                'entropy': self.compute_spectral_entropy(adj_eigenvalues)
            },
            'laplacian_spectrum': {
                'eigenvalues': lap_eigenvalues.tolist(),
                'spectral_gap': self.compute_spectral_gap(lap_eigenvalues),
                'statistics': self.compute_eigenvalue_statistics(lap_eigenvalues),
                'entropy': self.compute_spectral_entropy(lap_eigenvalues)
            },
            'trace_statistics': self.compute_trace_statistics(),
            'basic_stats': {
                'num_nodes': len(self.nodes),
                'num_hyperedges': len(self.hypergraphs),
                'avg_hyperedge_size': float(np.mean([len(e) for e in self.hypergraphs]))
            }
        }
        
        print("âœ… è°±åˆ†æå®Œæˆï¼")
        return results
    
    @staticmethod
    def compute_spectral_distance(results1: Dict, results2: Dict) -> Dict:
        """
        è®¡ç®—ä¸¤ä¸ªè¶…å›¾ä¹‹é—´çš„è°±è·ç¦»
        
        åŸºäº Louis (2015) çš„æ–¹æ³•:
        
        è·ç¦»åº¦é‡:
        1. ç‰¹å¾å€¼æ¬§æ°è·ç¦»
        2. ç‰¹å¾å€¼ä½™å¼¦è·ç¦»
        3. KLæ•£åº¦
        4. Wassersteinè·ç¦»
        """
        print("\nğŸ“ è®¡ç®—è°±è·ç¦»...")
        
        # æå–ç‰¹å¾å€¼
        eig1_adj = np.array(results1['adjacency_spectrum']['eigenvalues'])
        eig2_adj = np.array(results2['adjacency_spectrum']['eigenvalues'])
        
        eig1_lap = np.array(results1['laplacian_spectrum']['eigenvalues'])
        eig2_lap = np.array(results2['laplacian_spectrum']['eigenvalues'])
        
        # ç¡®ä¿é•¿åº¦ç›¸åŒï¼ˆå–è¾ƒçŸ­çš„ï¼‰
        min_len_adj = min(len(eig1_adj), len(eig2_adj))
        min_len_lap = min(len(eig1_lap), len(eig2_lap))
        
        eig1_adj = eig1_adj[:min_len_adj]
        eig2_adj = eig2_adj[:min_len_adj]
        eig1_lap = eig1_lap[:min_len_lap]
        eig2_lap = eig2_lap[:min_len_lap]
        
        distances = {
            'adjacency_distances': {},
            'laplacian_distances': {},
            'statistical_distances': {}
        }
        
        # æ¬§æ°è·ç¦»
        if min_len_adj > 0:
            distances['adjacency_distances']['euclidean'] = float(
                euclidean(eig1_adj, eig2_adj)
            )
            distances['adjacency_distances']['cosine'] = float(
                cosine(eig1_adj, eig2_adj)
            )
        
        if min_len_lap > 0:
            distances['laplacian_distances']['euclidean'] = float(
                euclidean(eig1_lap, eig2_lap)
            )
            distances['laplacian_distances']['cosine'] = float(
                cosine(eig1_lap, eig2_lap)
            )
        
        # ç»Ÿè®¡è·ç¦»
        stats1_adj = results1['adjacency_spectrum']['statistics']
        stats2_adj = results2['adjacency_spectrum']['statistics']
        
        distances['statistical_distances']['mean_diff'] = abs(
            stats1_adj['mean'] - stats2_adj['mean']
        )
        distances['statistical_distances']['std_diff'] = abs(
            stats1_adj['std'] - stats2_adj['std']
        )
        distances['statistical_distances']['entropy_diff'] = abs(
            results1['adjacency_spectrum']['entropy'] - 
            results2['adjacency_spectrum']['entropy']
        )
        
        # è°±é—´éš™å·®å¼‚
        distances['laplacian_distances']['spectral_gap_diff'] = abs(
            results1['laplacian_spectrum']['spectral_gap'] -
            results2['laplacian_spectrum']['spectral_gap']
        )
        
        print("âœ… è°±è·ç¦»è®¡ç®—å®Œæˆï¼")
        return distances


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python hypergraph_spectral_similarity.py <hypergraph_file>")
        print("ç¤ºä¾‹: python hypergraph_spectral_similarity.py LLM_Email_hypergraph.txt")
        return
    
    hypergraph_file = sys.argv[1]
    
    # è®¡ç®—è°±åˆ†æ
    hss = HypergraphSpectralSimilarity(hypergraph_file)
    results = hss.compute_all_metrics(k_eigenvalues=50)
    
    # ä¿å­˜ç»“æœ
    output_file = hypergraph_file.replace('.txt', '_spectral_similarity.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ ç»“æœå·²ä¿å­˜è‡³: {output_file}")
    print(f"\nä¸»è¦æŒ‡æ ‡:")
    print(f"  - é‚»æ¥çŸ©é˜µè°±åŠå¾„: {results['adjacency_spectrum']['spectral_radius']:.4f}")
    print(f"  - æ‹‰æ™®æ‹‰æ–¯è°±é—´éš™: {results['laplacian_spectrum']['spectral_gap']:.4f}")
    print(f"  - é‚»æ¥è°±ç†µ: {results['adjacency_spectrum']['entropy']:.4f}")
    print(f"  - æ‹‰æ™®æ‹‰æ–¯è°±ç†µ: {results['laplacian_spectrum']['entropy']:.4f}")


if __name__ == '__main__':
    main()

